val_loss : 1020.1824340820312 | time : 8.463736295700073 | batch : 0
Validation Epoch end... Loss : 0.001756748562979304
train_loss : 1017.1719970703125 | time : 5.130150079727173 | batch : 0
train_loss : 618.8707275390625 | time : 4.608281373977661 | batch : 100
train_loss : 392.41790771484375 | time : 5.082987070083618 | batch : 200
train_loss : 270.19378662109375 | time : 4.637412786483765 | batch : 300
train_loss : 198.97659301757812 | time : 4.654038429260254 | batch : 400
train_loss : 152.73233032226562 | time : 4.590090036392212 | batch : 500
train_loss : 123.6939926147461 | time : 4.2720136642456055 | batch : 600
train_loss : 101.71400451660156 | time : 4.913583517074585 | batch : 700
train_loss : 86.52713775634766 | time : 4.644882917404175 | batch : 800
train_loss : 75.10128784179688 | time : 4.683443307876587 | batch : 900
train_loss : 64.70530700683594 | time : 4.593502521514893 | batch : 1000
train_loss : 57.99298095703125 | time : 4.9141786098480225 | batch : 1100
train_loss : 51.136871337890625 | time : 4.632738351821899 | batch : 1200
train_loss : 46.49932098388672 | time : 4.550137281417847 | batch : 1300
train_loss : 42.37664794921875 | time : 4.513081789016724 | batch : 1400
train_loss : 39.10520553588867 | time : 4.343181371688843 | batch : 1500
train_loss : 35.39582061767578 | time : 4.935622215270996 | batch : 1600
train_loss : 33.438087463378906 | time : 4.629418134689331 | batch : 1700
train_loss : 31.06686782836914 | time : 4.461796522140503 | batch : 1800
train_loss : 28.674774169921875 | time : 4.624767303466797 | batch : 1900
train_loss : 27.10421371459961 | time : 4.65214729309082 | batch : 2000
train_loss : 25.643281936645508 | time : 4.640090703964233 | batch : 2100
Train Epoch end... Loss : 0.00032698904605933427
val_loss : 0.05095119774341583 | time : 6.961285591125488 | batch : 0
val_loss : 0.05016308277845383 | time : 6.698208332061768 | batch : 50
val_loss : 0.04913991689682007 | time : 6.65885066986084 | batch : 100
val_loss : 0.052494876086711884 | time : 6.612259387969971 | batch : 150
val_loss : 0.04899239540100098 | time : 6.490712404251099 | batch : 200
val_loss : 0.051304563879966736 | time : 6.485212564468384 | batch : 250
Validation Epoch end... Loss : 8.514543852622055e-08
train_loss : 24.47199058532715 | time : 5.776579141616821 | batch : 0
train_loss : 23.06087875366211 | time : 4.836201906204224 | batch : 100
train_loss : 22.255956649780273 | time : 4.716286659240723 | batch : 200
train_loss : 20.76277732849121 | time : 4.573032855987549 | batch : 300
train_loss : 19.753231048583984 | time : 4.871230840682983 | batch : 400
train_loss : 18.99999237060547 | time : 4.654181480407715 | batch : 500
train_loss : 18.298267364501953 | time : 4.768953084945679 | batch : 600
train_loss : 17.207103729248047 | time : 5.0496814250946045 | batch : 700
train_loss : 16.630535125732422 | time : 4.792404413223267 | batch : 800
train_loss : 15.999568939208984 | time : 4.143907070159912 | batch : 900
train_loss : 15.068578720092773 | time : 4.563525915145874 | batch : 1000
train_loss : 14.684823036193848 | time : 4.863391637802124 | batch : 1100
train_loss : 14.014052391052246 | time : 4.6943442821502686 | batch : 1200
train_loss : 13.653345108032227 | time : 4.5906291007995605 | batch : 1300
train_loss : 12.961857795715332 | time : 4.348656177520752 | batch : 1400
train_loss : 12.665656089782715 | time : 4.359264373779297 | batch : 1500
train_loss : 12.016066551208496 | time : 4.4117591381073 | batch : 1600
train_loss : 11.673675537109375 | time : 4.463125944137573 | batch : 1700
train_loss : 11.020467758178711 | time : 4.436530590057373 | batch : 1800
train_loss : 10.843011856079102 | time : 4.789962530136108 | batch : 1900
train_loss : 10.178950309753418 | time : 4.891165256500244 | batch : 2000
train_loss : 9.917542457580566 | time : 4.920773983001709 | batch : 2100
Train Epoch end... Loss : 3.672032806114662e-05
val_loss : 0.025939922779798508 | time : 6.665496826171875 | batch : 0
val_loss : 0.024066053330898285 | time : 6.518051624298096 | batch : 50
val_loss : 0.02321825735270977 | time : 6.684610366821289 | batch : 100
val_loss : 0.02805749885737896 | time : 6.571701765060425 | batch : 150
val_loss : 0.021369529888033867 | time : 6.28173041343689 | batch : 200
val_loss : 0.02560603991150856 | time : 6.3128838539123535 | batch : 250
Validation Epoch end... Loss : 4.1726705300381616e-08
train_loss : 9.751288414001465 | time : 5.379586935043335 | batch : 0
train_loss : 9.418327331542969 | time : 4.677966117858887 | batch : 100
train_loss : 8.912793159484863 | time : 4.281169652938843 | batch : 200
train_loss : 8.801750183105469 | time : 4.186276197433472 | batch : 300
train_loss : 8.504749298095703 | time : 4.676391124725342 | batch : 400
train_loss : 8.092092514038086 | time : 4.7407426834106445 | batch : 500
train_loss : 7.767480373382568 | time : 4.484930753707886 | batch : 600
train_loss : 7.5504608154296875 | time : 4.706967830657959 | batch : 700
train_loss : 7.322917461395264 | time : 4.323330640792847 | batch : 800
train_loss : 7.118315696716309 | time : 5.214528799057007 | batch : 900
train_loss : 6.830103397369385 | time : 4.3853795528411865 | batch : 1000
train_loss : 6.610054016113281 | time : 4.5298967361450195 | batch : 1100
train_loss : 6.423192024230957 | time : 4.299856424331665 | batch : 1200
train_loss : 6.190999984741211 | time : 5.129617214202881 | batch : 1300
train_loss : 6.050485134124756 | time : 4.485411882400513 | batch : 1400
train_loss : 5.729857444763184 | time : 4.982038497924805 | batch : 1500
train_loss : 5.544879913330078 | time : 4.467688322067261 | batch : 1600
train_loss : 5.355991363525391 | time : 4.806018590927124 | batch : 1700
train_loss : 5.1972222328186035 | time : 5.0441765785217285 | batch : 1800
train_loss : 5.1190080642700195 | time : 4.779372453689575 | batch : 1900
train_loss : 4.853242874145508 | time : 4.5378806591033936 | batch : 2000
train_loss : 4.712427616119385 | time : 4.599488973617554 | batch : 2100
Train Epoch end... Loss : 1.6144393270138277e-05
val_loss : 0.03010653145611286 | time : 6.867250204086304 | batch : 0
val_loss : 0.03125230595469475 | time : 6.894974231719971 | batch : 50
val_loss : 0.028942113742232323 | time : 6.803839921951294 | batch : 100
val_loss : 0.032490324229002 | time : 6.5654685497283936 | batch : 150
val_loss : 0.02721250057220459 | time : 6.42027473449707 | batch : 200
val_loss : 0.030531324446201324 | time : 6.510966777801514 | batch : 250
Validation Epoch end... Loss : 5.132573196606121e-08
train_loss : 4.525051593780518 | time : 5.5624144077301025 | batch : 0
train_loss : 4.467950344085693 | time : 4.599066495895386 | batch : 100
train_loss : 4.394373893737793 | time : 4.45052433013916 | batch : 200
train_loss : 4.199309349060059 | time : 4.7160325050354 | batch : 300
train_loss : 3.9655325412750244 | time : 5.059637546539307 | batch : 400
train_loss : 3.8893203735351562 | time : 4.467549562454224 | batch : 500
train_loss : 3.8094353675842285 | time : 4.341555595397949 | batch : 600
train_loss : 3.6057910919189453 | time : 4.643657207489014 | batch : 700
train_loss : 3.4848434925079346 | time : 4.2430243492126465 | batch : 800
train_loss : 3.319481134414673 | time : 4.623533725738525 | batch : 900
train_loss : 3.291038990020752 | time : 4.797665119171143 | batch : 1000
train_loss : 3.194365978240967 | time : 4.49394679069519 | batch : 1100
train_loss : 3.066497564315796 | time : 4.536911249160767 | batch : 1200
train_loss : 3.0094854831695557 | time : 4.493631839752197 | batch : 1300
train_loss : 2.8555355072021484 | time : 4.7652928829193115 | batch : 1400
train_loss : 2.775784492492676 | time : 4.566165924072266 | batch : 1500
train_loss : 2.6319808959960938 | time : 4.548241853713989 | batch : 1600
train_loss : 2.596240520477295 | time : 4.482234239578247 | batch : 1700
train_loss : 2.5112102031707764 | time : 4.524954319000244 | batch : 1800
train_loss : 2.419121742248535 | time : 4.80482816696167 | batch : 1900
train_loss : 2.3543875217437744 | time : 4.444165229797363 | batch : 2000
train_loss : 2.2730214595794678 | time : 4.549046039581299 | batch : 2100
Train Epoch end... Loss : 7.760863950463908e-06
val_loss : 0.009306316263973713 | time : 6.601346492767334 | batch : 0
val_loss : 0.009008617140352726 | time : 6.369891405105591 | batch : 50
val_loss : 0.00928548164665699 | time : 6.617788076400757 | batch : 100
val_loss : 0.00946942251175642 | time : 6.365689516067505 | batch : 150
val_loss : 0.008269245736300945 | time : 6.524431228637695 | batch : 200
val_loss : 0.009030507877469063 | time : 6.395571947097778 | batch : 250
Validation Epoch end... Loss : 1.7214668588823883e-08
train_loss : 2.2042412757873535 | time : 5.5873565673828125 | batch : 0
train_loss : 2.157210111618042 | time : 4.451463937759399 | batch : 100
train_loss : 2.071424961090088 | time : 4.371851921081543 | batch : 200
train_loss : 1.9867222309112549 | time : 4.679509401321411 | batch : 300
train_loss : 1.983992338180542 | time : 4.929187059402466 | batch : 400
train_loss : 1.8803521394729614 | time : 4.206990480422974 | batch : 500
train_loss : 1.8085392713546753 | time : 4.338221788406372 | batch : 600
train_loss : 1.753100872039795 | time : 4.312828779220581 | batch : 700
train_loss : 1.7241880893707275 | time : 4.568559646606445 | batch : 800
train_loss : 1.6541255712509155 | time : 4.965560674667358 | batch : 900
train_loss : 1.5723297595977783 | time : 4.62747049331665 | batch : 1000
train_loss : 1.5228382349014282 | time : 4.744693994522095 | batch : 1100
train_loss : 1.449434757232666 | time : 4.719395399093628 | batch : 1200
train_loss : 1.410111427307129 | time : 4.8160319328308105 | batch : 1300
train_loss : 1.3880681991577148 | time : 5.45732307434082 | batch : 1400
train_loss : 1.3419960737228394 | time : 4.83125901222229 | batch : 1500
train_loss : 1.273348093032837 | time : 4.878375768661499 | batch : 1600
train_loss : 1.2382107973098755 | time : 4.513318777084351 | batch : 1700
train_loss : 1.2004673480987549 | time : 4.459715843200684 | batch : 1800
train_loss : 1.154035210609436 | time : 4.830967426300049 | batch : 1900
train_loss : 1.1277894973754883 | time : 4.679620265960693 | batch : 2000
train_loss : 1.0875405073165894 | time : 4.64374303817749 | batch : 2100
Train Epoch end... Loss : 3.7298050535745144e-06
val_loss : 0.0074980896897614 | time : 6.950994491577148 | batch : 0
val_loss : 0.007310896180570126 | time : 6.556518793106079 | batch : 50
val_loss : 0.007665710523724556 | time : 6.604964971542358 | batch : 100
val_loss : 0.007937951944768429 | time : 6.901111602783203 | batch : 150
val_loss : 0.006919444538652897 | time : 6.416508674621582 | batch : 200
val_loss : 0.007571745663881302 | time : 7.025684118270874 | batch : 250
Validation Epoch end... Loss : 1.5549657667027646e-08
